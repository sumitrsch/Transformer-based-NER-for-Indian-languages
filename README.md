# Transformer-based-NER-for-Indian-languages
This repository contains different transformer based Deep learning models for NER task in Indian languages.
We have uploded trained muril-large model for ner task on train data of Hindi and Bangla.
Score can be generated by running code eval_test.py for evaluation on test data with  below command line arguments.
        model_version, best_model_path, test_data_file, model_max_length,  batch_size
        
        best_model_path =  "./best_model/Bangla_model" (for Bangla_data) or "./best_model/Hindi_model"  (for hindi data),
        model_version = "bangla muril_large" or "hindi_muril large" 
        test_data_file = "./preprocessed_data/NER_bangla_data.csv"   or "./preprocessed_data/NER_hindi_data.csv.csv"
        batch_size = 8
        

Step 1: Preprocessing
      
      This step will convert data from conll format to CSV format for attributes "sentence_id", "words" and "labels". 
      run preproccessing.py with below command line arguments.
      Path of three data files: train, valid and test 
      
 Step 2:Training
        
        run train.py with  below command line arguments.
        model_version, train_data-file, model_max_length, number_of_epochs, batch_size, learning_rate
        
 
 Step 3:Evaluation
        
        a.run eval_valid.py for evaluation on valid data with  below command line arguments.
        model_version, valid_data_file, model_max_length, number_of_epoch, batch_size
 
        b.  run eval_test.py for evaluation on test data with  below command line arguments.
        model_version, best_model_path, test_data_file, model_max_length,  batch_size
        
        best_model_path = Training saves model for each epoch. Select model which gives highest F1-score on valid_data.



model_version =  'ai4bharat/indic-bert' / 
                 'xlm-roberta-base' / 
                 'xlm-roberta-large' / 
                 'google/muril-large-cased' /
                 'google/muril-base-cased' / 
                 'bert-base-multilingual-cased'
